# Setup

Tested on Python 3.10 and 3.12

To setup environment install requirements.txt

```bash
pip install -r requirements.txt
```


## Running the project

To run the trained models on the modified Static Obstacle environment and Sector CR environment run the respective files:

### Static Obstacle Environment
- DDPG: `static_env_ddpg.py`  
- PPO: `static_env_ppo.py`

### Sector CR Environment
- DDPG: `sector_env_ddpg.py`  
- PPO: `sector_env_ppo.py`

## Citing

If you use BlueSky-Gym in your work, please cite it using:
```bibtex
@misc{bluesky-gym,
  author = {Groot, DJ and Leto, G and Vlaskin, A and Moec, A and Ellerbroek, J},
  title = {BlueSky-Gym: Reinforcement Learning Environments for Air Traffic Applications},
  year = {2024},
  journal = {SESAR Innovation Days 2024},
}
```

List of publications & preprints using `BlueSky-Gym` (please open a pull request to add missing entries):
*   _missing entry_
